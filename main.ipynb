{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRLPT194Wr5B"
      },
      "source": [
        "- Code written by Jamal\n",
        "- Annotated by Aidan\n",
        "- 1 of 3 Python scripts corresponding to \"Toward Fairness in Face Matching Algorithms\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flYYhxe-bm1q"
      },
      "source": [
        "# # I think this is looking at files from a file tree and identifying duplicates ???\n",
        "\n",
        "# from os import listdir\n",
        "# import shutil\n",
        "# from os.path import isfile, join\n",
        "\n",
        "# # root directory\n",
        "\n",
        "# img_path = \"/home/jamal/Desktop/LFW attributes/lfw/\"\n",
        "\n",
        "# # output directory \n",
        "# save_path = \"/home/jamal/Desktop/LFW attributes/more_than_once/\"\n",
        "\n",
        "# onlyfiles = [f for f in listdir(img_path)]\n",
        "# \n",
        "# for i in range(len(onlyfiles)):\n",
        "#     tem_path = img_path + onlyfiles[i]\n",
        "#     if len(listdir(tem_path))>1:\n",
        "#         s_path = save_path + onlyfiles[i]\n",
        "#         shutil.copytree(tem_path,s_path)\n",
        "#     print(i/len(onlyfiles))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4C3JzTWbpj2"
      },
      "source": [
        "# IMPORTING LIBARIES #\n",
        "\n",
        "# tabular data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# array manipulation\n",
        "import numpy as np\n",
        "\n",
        "# visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# operating system status\n",
        "import os\n",
        "\n",
        "# for resizing images\n",
        "from skimage import io, transform\n",
        "\n",
        "# library for adam optimizer\n",
        "import torch.optim as optim\n",
        "\n",
        "# DataLoader is a Python iterable over a dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# for grabbing a random set of images\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# for confusion matrix (model evaluation)\n",
        "import sklearn.metrics as mt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oaWld92b1zk"
      },
      "source": [
        "# additional files is located in /home/jamal/Downloads/additional_files/\n",
        "\n",
        "# tar file with main NN progress saves\n",
        "def save_checkpoint(state, filename='/home/jamal/Downloads/checkpoint_0.001.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "# tar file with adversarial NN progress saves\n",
        "def save_checkpoint_A(state, filename='/home/jamal/Downloads/checkpoint_A_0.001.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "# path to csv    \n",
        "file_path ='/home/jamal/Downloads/umdfaces_batch1_ultraface_new1.csv'\n",
        "\n",
        "# path to images\n",
        "images_path = '/home/jamal/Downloads/umdfaces_batch1/'\n",
        "\n",
        "# used for before and during/after a model is trained\n",
        "# main  = 0, testing = 0\n",
        "load_net = 0\n",
        "\n",
        "# attributes/columns for celebrity data set\n",
        "# columns = ['ImgId','5_o_Clock_Shadow', ' Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n",
        "\n",
        "# attributes/columns for UMD data set\n",
        "columns=['SUBJECT_ID','FILE','FACE_X','FACE_Y','FACE_H','FACE_W','PR_MALE','PR_FEMALE']\n",
        "\n",
        "# read celebrity csv\n",
        "cele_attrib = pd.read_csv(file_path,delimiter = \",\",names = columns)\n",
        "# # commented out setting the index according to the subject id\n",
        "# lfw = cele_attrib.set_index('SUBJECT_ID')\n",
        "# lfw = cele_attrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbG-sBE1g4Oh"
      },
      "source": [
        "# # just visualizing random images from the celebrity data set using matplotlib\n",
        "# len_attrib = len(cele_attrib)\n",
        "# Select random images form celeba dataset\n",
        "# rnd_set = np.random.permutation(len_attrib)[0:5]\n",
        "# for i in rnd_set:\n",
        "#     idx = (\"{:06d}.png\".format(i))\n",
        "#     img_path = images_path+idx\n",
        "#     img = plt.imread(img_path)\n",
        "#     plt.imshow(img)\n",
        "#     plt.show()\n",
        "#     print(cele_attrib['Male'][i-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOiZix5kb7Q5"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "# main neural network with both image inputs\n",
        "class Net(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Net,self).__init__()\n",
        "\n",
        "        # it seems like the size of the layers are different here than in the final paper (could be that Jamal used different py script)\n",
        "\n",
        "        # for large image (150 by 150) with 3 convulational/max-pooling layers \n",
        "        self.conv11 = nn.Conv2d(3,64,5)\n",
        "        self.n11 = nn.BatchNorm2d(64)\n",
        "        self.conv21 = nn.Conv2d(64,96,5)\n",
        "        self.n21 = nn.BatchNorm2d(96)\n",
        "        self.conv31 = nn.Conv2d(96,128,3)\n",
        "        self.n31 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # for small image (12 by 12) with 2 convulational/max-pooling layers\n",
        "        self.conv12 = nn.Conv2d(3,32,7)\n",
        "        self.n12 = nn.BatchNorm2d(32)\n",
        "        self.conv22 = nn.Conv2d(32,75,3)\n",
        "        self.n22 = nn.BatchNorm2d(75)\n",
        "        #self.conv32 = nn.Conv2d(75,100,3)\n",
        "        #self.n32 = nn.BatchNorm2d(100)\n",
        "        \n",
        "        # flattening occurs here\n",
        "\n",
        "        # for determining if the same face\n",
        "        self.ip1 = nn.Linear(1712,128)   # change the first parameter in case you change the size of the small image\n",
        "        self.ip2 = nn.Linear(128,\n",
        "                             # output corresponds to two nodes: one for same face and the other for different face? \n",
        "                             2)\n",
        "\n",
        "        # seems like this would be for the adversarial NN ? I think this code is actually not used for the main NN based on forward(self,x,y)\n",
        "        self.ip3 = nn.Linear(1712,128,\n",
        "                             # bias set to False, the layer will not learn an additive bias (Default: True)\n",
        "                             False)   # change the first parameter in case you change the size of the small image\n",
        "        self.ip4 = nn.Linear(128,\n",
        "                             # output corresponds to two nodes: one for female and the other for male?       \n",
        "                             2,\n",
        "                             # bias set to False, the layer will not learn an additive bias (Default: True)\n",
        "                             False)\n",
        "        \n",
        "    \n",
        "    def forward(self,x,y):\n",
        "        # large image\n",
        "        x = self.conv11(x)\n",
        "        x = self.n11(x)\n",
        "        x = F.relu(x)\n",
        "        # maxpooling\n",
        "        x = F.max_pool2d(x,5,stride = 3)\n",
        "        \n",
        "        x = self.conv21(x)\n",
        "        x = self.n21(x)\n",
        "        x = F.relu(x)\n",
        "        # maxpooling\n",
        "        x = F.max_pool2d(x,5,stride = 3)\n",
        "\n",
        "        x = self.conv31(x)\n",
        "        x = self.n31(x)\n",
        "        x = F.relu(x)\n",
        "        # maxpooling\n",
        "        x = F.max_pool2d(x,5)\n",
        "        # flattening large image\n",
        "        x = x.view(-1,512)\n",
        "        \n",
        "        # small image\n",
        "        y = self.conv12(y)\n",
        "        \n",
        "        y = self.n12(y)\n",
        "        y = F.relu(y)\n",
        "        # y = F.max_pool2d(y,5,stride = 1)\n",
        "        y = self.conv22(y)\n",
        "        y = self.n22(y)\n",
        "        y = F.relu(y)\n",
        "        # y = F.max_pool2d(y,5,stride = 2)\n",
        "                \n",
        "        # seems like Jamal originally tried this with three layers\n",
        "        # y = self.conv32(y)\n",
        "        # y = F.max_pool2d(y,3)\n",
        "        # y = self.n32(y)\n",
        "        # y = F.relu(y)\n",
        "\n",
        "        y = y.view(-1,1200)  # change the second parameter in case you change the size of the small image\n",
        "        \n",
        "        # FLATTENING! aka concatenating ?\n",
        "        x = torch.cat((x,y),1)\n",
        "        x1 = self.ip1(x)\n",
        "        x1 = F.relu(x1)\n",
        "        x1 = self.ip2(x1)\n",
        "\n",
        "        # x2 represents the large image in the adversarial network\n",
        "        # x2 = self.ip3(x)\n",
        "        # x2 = F.relu(x2)\n",
        "        # x2 = self.ip4(x2)\n",
        "        # x2 = x2.mul(-1)\n",
        "        # x = F.relu(x)\n",
        "        # x = F.softmax(x,1) # why remove softmax?\n",
        "        return x1, x\n",
        "      \n",
        "\n",
        "# adversarial neural network (male/female identifier)\n",
        "class Net_A(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Net_A,self).__init__()\n",
        "        \n",
        "        self.ip3 = nn.Linear(\n",
        "            # input = size of flattened image\n",
        "            1712,\n",
        "            # output (heavily condensing)\n",
        "            128,\n",
        "            # bias set to False, the layer will not learn an additive bias (Default: True)\n",
        "            False)   # change the first parameter in case you change the size of the small image\n",
        "        \n",
        "        # Relu between layers    \n",
        "        \n",
        "        self.ip4 = nn.Linear(128,\n",
        "                             # output corresponds to two nodes: one for female and the other for male ?\n",
        "                             2,\n",
        "                             # bias set to False, the layer will not learn an additive bias (Default: True)\n",
        "                             False)\n",
        "        \n",
        "    \n",
        "    def forward(self,x):\n",
        "        # takes only the larger image as an input to test in the model\n",
        "        x2 = self.ip3(x)\n",
        "        x2 = F.relu(x2)\n",
        "        x2 = self.ip4(x2)\n",
        "        # x2 = x2.mul(-1)\n",
        "        # x = F.relu(x)\n",
        "        # x = F.softmax(x,1)\n",
        "        return x2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCh_H_LFdAmr"
      },
      "source": [
        "# for resizing images\n",
        "class Male_Female_dataset(Dataset):\n",
        "\n",
        "    def __init__(self,root_dir,shape,transform=None):\n",
        "        # directory of csv\n",
        "        self.root_dir = root_dir\n",
        "        # no transformations\n",
        "        self.transform = transform\n",
        "        # shape of image\n",
        "        self.shape = shape\n",
        "        # directory of images \n",
        "        self.images_names = os.listdir(images_path)\n",
        "        \n",
        "    def __len__(self):\n",
        "        # get the number of celebrity attributes  \n",
        "        return len(cele_attrib)\n",
        "        \n",
        "    def __getitem__(self,idx):\n",
        "        # tensor of 1 random representing random uniform scaler => balanced data set\n",
        "        # 50% likelyhood of creating a low resolution version of the same person \n",
        "        # 50% likelyhood of creating a low resolution version of a different person \n",
        "        t = torch.rand(1);\n",
        "        # convert row (image) at a given index (argument/idx) to list \n",
        "        lst = cele_attrib.loc[idx].tolist()\n",
        "        # get image name\n",
        "        img1_name = os.path.join(self.root_dir,lst[1])\n",
        "        # input reading of image according to name\n",
        "        image1 = io.imread(img1_name)\n",
        "        # ['SUBJECT_ID','FILE','FACE_X','FACE_Y','FACE_H','FACE_W','PR_MALE','PR_FEMALE'] ??? I really am not sure about this one?\n",
        "        # Face Y Position + Face Width ?\n",
        "        # Face X Position + Face Height ?\n",
        "        image1 = image1[int(lst[3]):int(lst[3]+lst[5]),int(lst[2]):int(lst[2]+lst[4]),:]\n",
        "        # import cv2\n",
        "        # cv2.imshow('a',img)\n",
        "        # cv2.waitKey(1000)\n",
        "        # cv2.destroyAllWindows()\n",
        "        \n",
        "        # resizing to 150 by 150\n",
        "        image1 = transform.resize(image1,(150,150))\n",
        "       \n",
        "        # 50% likelyhood of creating a low resolution version of a different person\n",
        "        if t > 0.5: #different\n",
        "            different = False\n",
        "            while not(different):\n",
        "                h = torch.randint(0,len(self),(1,1))\n",
        "                ht = torch.Tensor.numpy(h)\n",
        "                if lfw.loc[idx][0] != lfw.loc[int(ht[0])][0]:\n",
        "                    different = True\n",
        "            \n",
        "            lstd = cele_attrib.loc[int(ht[0])].tolist()        \n",
        "                \n",
        "            img2_name = os.path.join(self.root_dir,lstd[1])\n",
        "            image2 = io.imread(img2_name)\n",
        "            image2 = image2[int(lstd[3]):int(lstd[3]+lstd[5]),int(lstd[2]):int(lstd[2]+lstd[4]),:]\n",
        "            # import cv2\n",
        "            # cv2.imshow('a',image2)\n",
        "            # cv2.waitKey(1000)\n",
        "            # cv2.destroyAllWindows()\n",
        "            image2 = transform.resize(image2,self.shape)\n",
        "            image2 = torch.Tensor.float(torch.from_numpy(image2))\n",
        "            image2 = (torch.Tensor.permute(image2,(2,0,1)))\n",
        "            image2 = image2/256.0\n",
        "            image1 = torch.Tensor.float(torch.from_numpy(image1))\n",
        "            image1 = (torch.Tensor.permute(image1,(2,0,1)))\n",
        "            image1 = image1/256.0\n",
        "            annot = 0\n",
        "            gender =  1 if lst[-2]>.5 else -1\n",
        "\n",
        "        # 50% likelyhood of creating a low resolution version of the same person     \n",
        "        else: \n",
        "            id = cele_attrib.loc[idx].tolist()[0]\n",
        "            idx_new = idx+1\n",
        "            if  cele_attrib.loc[idx+1].tolist()[0]==id:\n",
        "                lstd = cele_attrib.loc[idx+1].tolist()\n",
        "                sta = os.path.join(self.root_dir,lstd[1])\n",
        "            else:\n",
        "                lstd = cele_attrib.loc[idx-1].tolist()\n",
        "                sta = os.path.join(self.root_dir,lstd[1])\n",
        "            # st = img1_name.split('/')\n",
        "            # st = st[-1]\n",
        "            # st = st.split('_')\n",
        "            # nn = st[0:-1]\n",
        "            # name = ' '.join(nn)\n",
        "            # num = int(st[-1].split('.')[0])\n",
        "            \n",
        "            # cc = lfw.loc[name]\n",
        "            # if isinstance(cc.imagenum,str):\n",
        "            #     print(cc)\n",
        "            # ls = cc.imagenum.tolist()\n",
        "            # if str(num) in ls:\n",
        "            #     ls.remove(str(num))\n",
        "            # \n",
        "            # h = torch.randint(0,len(ls),(1,1))\n",
        "            # ht = torch.Tensor.numpy(h)\n",
        "            # ht = ht[0]\n",
        "            # num2 = str(int(ls[int(ht)])).zfill(4)\n",
        "            # sta = img1_name.split('_')\n",
        "            # stemp = sta[-1].split('.')\n",
        "            # stemp[0] = num2\n",
        "            # stemp = '.'.join(stemp)\n",
        "            # sta[-1]=stemp\n",
        "            # sta = '_'.join(sta)\n",
        "            image2 = io.imread(sta)\n",
        "            image2 = transform.resize(image2,self.shape)\n",
        "            image2 = torch.Tensor.float(torch.from_numpy(image2))\n",
        "            image2 = (torch.Tensor.permute(image2,(2,0,1)))\n",
        "            image2 = image2/256.0\n",
        "            image1 = torch.Tensor.float(torch.from_numpy(image1))\n",
        "            image1 = (torch.Tensor.permute(image1,(2,0,1)))\n",
        "            image1 = image1/256.0\n",
        "            annot = 1\n",
        "            gender = 1 if lst[-2]>.5 else -1\n",
        "        # annot = annot.astype('float').reshape(-1,2)\n",
        "        sample = {'image1':image1,'image2':image2, 'same' : annot, 'gender' : gender}\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2B7mwV2uclB"
      },
      "source": [
        "## Execution Script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYtGS9uQ999Z"
      },
      "source": [
        "# use_cuda is true if cuda is available to use for GPU capabilities\n",
        "use_cuda = torch.cuda.is_available()\n",
        "# use_cuda=0\n",
        "# if cude is not available, use CPU\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "# prints whether the processing devise is a CPU or cuda GPU\n",
        "print(device)\n",
        "# shape of smaller image\n",
        "shape = (12,12)\n",
        "# shape of larger image\n",
        "ip_shape = (150,150)\n",
        "# 80% of data will be used for training\n",
        "train_ratio = 0.8\n",
        "# remaining 20% of data will be used for validation (most)\n",
        "val_ratio = 0.2\n",
        "# for actual test, training and validation ratio will both be zero and test ratio will be 1\n",
        "test_ratio = 1-train_ratio-val_ratio\n",
        "# create data set object!\n",
        "dataset = Male_Female_dataset(images_path,shape)\n",
        "# dataset.__getitem__(175534-1)\n",
        "\n",
        "# if load_net == 1 (loading) -> testing\n",
        "if load_net:\n",
        "    # run both nets on either cpu or gpu (CUDA)\n",
        "    net = Net().to(device)\n",
        "    net_A = Net_A().to(device)\n",
        "\n",
        "    # NOTE: checkpoints save epoch #, state, and optimizer\n",
        "\n",
        "    # loading NN from last checkpoint where checkpoint \n",
        "    checkpoint = torch.load('/home/jamal/Downloads/additional_files/checkpoint_0.001.pth.tar')\n",
        "    # loading adversarial NN from last checkpoint where \n",
        "    checkpoint_A = torch.load('/home/jamal/Downloads/additional_files/checkpoint_A_0.001.pth.tar')\n",
        "\n",
        "    # loading main NN checkpoint where checkpoint \n",
        "    net.load_state_dict ( checkpoint['state_dict'])\n",
        "    # using adam optimizer for backpropagation\n",
        "    optimizer = optim.Adam(net.parameters(),\n",
        "                           # learning rate of 0.001\n",
        "                           lr = 0.001, \n",
        "                           # learning rate decay of .0005\n",
        "                           weight_decay = 0.0005)\n",
        "    optimizer.load_state_dict = checkpoint['optimizer']\n",
        "    \n",
        "    # loading adversarial NN checkpoint state\n",
        "    net_A.load_state_dict ( checkpoint_A['state_dict'])\n",
        "    # using adam optimizer for backpropagation\n",
        "    optimizer_A = optim.Adam(net_A.parameters(),\n",
        "                             # learning rate of 0.001\n",
        "                             lr = 0.001,\n",
        "                             # learning rate decay of .0005\n",
        "                             weight_decay = 0.0005)\n",
        "    # loading adversarial NN checkpoint optizer\n",
        "    optimizer_A.load_state_dict = checkpoint_A['optimizer']\n",
        "\n",
        "# if load_net == 0 (not loading) -> development\n",
        "else:\n",
        "    # instantiating main NN to be run on cpu or gpu\n",
        "    net = Net().to(device)\n",
        "    # instantiating adversarial NN\n",
        "    net_A = Net_A().to(device)\n",
        "    # adam optimizer, .001 learning rate, and .0005 weight decay for backpropagation of both NN\n",
        "    optimizer = optim.Adam(net.parameters(),lr = 0.001, weight_decay = 0.0005)\n",
        "    optimizer_A = optim.Adam(net_A.parameters(),lr = 0.001, weight_decay = 0.0005)\n",
        "    # setting checkpoint epochs to zero\n",
        "    checkpoint= {'epoch':0}\n",
        "    \n",
        "# optimizer = optim.Adam(net.parameters(),lr = 0.001, weight_decay = 0.0005)\n",
        "# optimizer_A = optim.Adam(net.parameters(),lr = 0.001, weight_decay = 0.0005)\n",
        "\n",
        "# create randomize numpy array with index numbers ranging from 0 to 5 less than the size of the data set\n",
        "# not sure why it is -5?\n",
        "index = np.random.permutation(len(dataset)-5)\n",
        "# number of entries in the training data set\n",
        "train_data_length = int(train_ratio*len(index))\n",
        "# number of entries in the validation data set\n",
        "val_data_length = int(val_ratio*len(index))\n",
        "# number of entries in the testing data set\n",
        "test_data_length = int(test_ratio*len(index))\n",
        "# train data indexes correspond to index 0 of index array to train data length \n",
        "train_index = index[:train_data_length]\n",
        "# validation data indexes correspond to the index values of train data length to validation data length   \n",
        "val_index = index[train_data_length:(train_data_length+val_data_length)]\n",
        "# test data indexes correspond to the index values of  validation data length to test data length   \n",
        "test_index = index[train_data_length+val_data_length:]\n",
        "\n",
        "# load data \n",
        "train_dataloader = DataLoader( # more or less a series of image paths\n",
        "                              dataset,\n",
        "                              # number of samples per load\n",
        "                              batch_size=100,\n",
        "                              # numpy array generated a couple lines above is used as method for sampling from dataset\n",
        "                              sampler = SubsetRandomSampler(train_index))\n",
        "\n",
        "# error of face matching\n",
        "err_same = []\n",
        "# error of gender matching\n",
        "err_gender = []\n",
        "\n",
        "# accuracy of face matching\n",
        "acc1 = []\n",
        "# accuracy of gender matching\n",
        "acc2 = []\n",
        "\n",
        "# minimization criterion of face matching NN\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# minimization criterion of gender matching NN\n",
        "criterion2 = nn.CrossEntropyLoss()\n",
        "\n",
        "# not sure what t is ? it's only use seems to be commented out\n",
        "t = -1\n",
        "\n",
        "# run for 5 epochs\n",
        "for ep in range(checkpoint['epoch'],5):\n",
        "    for i,data in enumerate(train_dataloader):\n",
        "        \n",
        "        # Zeros descent gradient to help generalize after each batch\n",
        "        optimizer.zero_grad()\n",
        "        optimizer_A.zero_grad()\n",
        "        \n",
        "        # input1 = high res true image\n",
        "        # input2 = low res true or false image\n",
        "        # label = name corresponding to true image path\n",
        "        # gender = male or female label\n",
        "        input1, input2 , label, gender = data.items()\n",
        "        # run on cuda gpu if available\n",
        "        input1, input2 = input1[1].to(device), input2[1].to(device)\n",
        "        label1 = label[1].to(device)\n",
        "        gender = gender[1].to(device)\n",
        "        # not sure why it is (gender+1)/2? \n",
        "        gender = (gender+1)/2\n",
        "        #label = torch.Tensor.long(label[1])\n",
        "        \n",
        "        # feed input images 1 and 2 into neural network\n",
        "        output = net(input1,input2)\n",
        "        # feed output of main face matching NN to gender matching NN\n",
        "        output_A = net_A(output[1])\n",
        "\n",
        "        # use cross entropy loss as minimization criterion for both main an adv. NN\n",
        "        # use true image as label\n",
        "        loss1 = criterion (output[0],label1)\n",
        "        #loss1.backward(retain_graph=True)\n",
        "        # optimizer.step()\n",
        "\n",
        "        # use gender as label\n",
        "        loss2 = criterion2 (output_A,gender)\n",
        "        \n",
        "        # backwards propagation \n",
        "        # not sure why retain graph ? In essence, it will retain any necessary information to calculate a certain variable, so that we can do backward pass on it.\n",
        "        loss2.backward(retain_graph=True)\n",
        "        # gender matching NN gradient step\n",
        "        optimizer_A.step()\n",
        "\n",
        "        # formula: L = Ly - wLd\n",
        "        loss1 = loss1 - loss2.mul(1)  #new line \n",
        "        #loss2 = loss2.abs()\n",
        "        # t = t*-1\n",
        "\n",
        "        # backwards propagation \n",
        "        loss1.backward()\n",
        "        # face matching NN gradient step\n",
        "        optimizer.step()\n",
        "        # adding loss as an entry to face matching list\n",
        "        err_same.append(loss1.item())\n",
        "        # adding loss as an entry to face matching list\n",
        "        err_gender.append(loss2.item())\n",
        "\n",
        "        # if 5th iteration, print the loss, iteration #, and epoch for each of the NN\n",
        "        if (i%5==0):\n",
        "            print (loss1,i,ep)\n",
        "            print (loss2,i,ep)\n",
        "            #print (output[1])\n",
        "\n",
        "        # if 50th iteration, check accuracy of model          \n",
        "        if (i%50==0):\n",
        "            # create a numpy array from the indexes from the validation array\n",
        "            val_index1 = np.random.permutation(val_index)[:100]\n",
        "            # test for accuracy using 30 images from validation data \n",
        "            val_dataloader = DataLoader(dataset,batch_size=30,sampler = SubsetRandomSampler(val_index1))\n",
        "            # make validation data iterable\n",
        "            val_iter = iter(val_dataloader)\n",
        "\n",
        "            # counter variables\n",
        "            total = 0\n",
        "            correct1 = 0\n",
        "            correct2 = 0\n",
        "            # literally just going through and checking if the model predicts the true value (same face / which gender) correctly\n",
        "            for j,dataj in enumerate(val_dataloader):\n",
        "                input1j, input2j, labelj, gender = dataj.items()\n",
        "                input1j, input2j = input1j[1].to(device), input2j[1].to(device)\n",
        "                \n",
        "                labelj = labelj[1].to(device)\n",
        "                gender = gender[1].to(device)\n",
        "                gender = (gender+1)/2\n",
        "                output = net(input1j,input2j)\n",
        "                output_A = net_A(output[1])\n",
        "                _,predicted1 = torch.max(output[0].data,1)\n",
        "                _,predicted2 = torch.max(output_A.data,1)\n",
        "                total +=labelj.size(0)\n",
        "                correct1 += (predicted1 == labelj).sum().item()\n",
        "                correct2 += (predicted2 == gender).sum().item()\n",
        "            # prints out percent accurate for both NN\n",
        "            print('Accuracy_LH: %d %%'%(100*correct1/total))\n",
        "            print('Accuracy_MF: %d %%'%(100*correct2/total))\n",
        "            \n",
        "            # record the percent accurate for both NN into respective lists\n",
        "            acc1.append(100*correct1/total) #low high\n",
        "            acc2.append(100*correct2/total) # male female\n",
        "\n",
        "    # outside of inner loop\n",
        "    # saves for every epoch\n",
        "\n",
        "    # save the checkpoint to be loaded for next use\n",
        "    save_checkpoint({\n",
        "            # increase the track of the current epoch #\n",
        "            'epoch': ep + 1,\n",
        "            # save Python dictionary object that maps each layer to its parameter tensor.\n",
        "            'state_dict': net.state_dict(),\n",
        "            # update optimizer conditions (because it may not be zeroed)\n",
        "            'optimizer' : optimizer.state_dict(),\n",
        "        })\n",
        "    save_checkpoint_A({\n",
        "            'epoch': ep + 1,\n",
        "            'state_dict': net_A.state_dict(),\n",
        "            \n",
        "            'optimizer' : optimizer_A.state_dict(),\n",
        "        })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cEiZvGkcA4T"
      },
      "source": [
        "# FOR CELEB DATA SET #\n",
        "  \n",
        "# val_index1 = np.random.permutation(val_index)[:100]\n",
        "# val_dataloader = DataLoader(dataset,batch_size=30)\n",
        "# val_iter = iter(val_dataloader)\n",
        "# predicted_lables = []\n",
        "# real_labels_g = []\n",
        "# predicted_lables_g = []\n",
        "# real_labels = []\n",
        "# total = 0\n",
        "# correct1 = 0\n",
        "# correct2 = 0\n",
        "# for j,dataj in enumerate(val_dataloader):\n",
        "#     input1j, input2j, labelj, gender = dataj.items()\n",
        "#     input1j, input2j = input1j[1].to(device), input2j[1].to(device)\n",
        "#     \n",
        "#     labelj = labelj[1].to(device)\n",
        "#     gender = gender[1].to(device)\n",
        "#     gender = (gender+1)/2\n",
        "#     output = net(input1j,input2j)\n",
        "#     _,predicted1 = torch.max(output[0].data,1)\n",
        "#     _,predicted2 = torch.max(output[1].data,1)\n",
        "#     total +=labelj.size(0)\n",
        "#     correct1 += (predicted1 == labelj).sum().item()\n",
        "#     correct2 += (predicted2 == gender).sum().item()\n",
        "#     predicted_lables.append(torch.Tensor.numpy(predicted1))\n",
        "#     real_labels.append(torch.Tensor.numpy(labelj))\n",
        "#     \n",
        "#     predicted_lables_g.append(torch.Tensor.numpy(predicted2))\n",
        "#     real_labels_g.append(torch.Tensor.numpy(gender))\n",
        "#     print('Accuracy_LH: %d %%'%(100*correct1/total))\n",
        "#     print('Accuracy_MF: %d %%'%(100*correct2/total))\n",
        "#     acc1.append(100*correct1/total)\n",
        "#     acc2.append(100*correct2/total)\n",
        "#     print(mt.confusion_matrix(np.array(real_labels).flatten(),np.array(predicted_lables).flatten()))\n",
        "#     \n",
        "#     print(mt.confusion_matrix(np.array(real_labels_g).flatten(),np.array(predicted_lables_g).flatten()))\n",
        "# # for ep in range(checkpoint['epoch'],5):\n",
        "#     for i,data in enumerate(train_dataloader):\n",
        "#         optimizer.zero_grad()\n",
        "#         input1, input2 , label = data.items()\n",
        "#         input1, input2 = input1[1].to(device), input2[1].to(device)\n",
        "#         label1 = label[1].to(device)\n",
        "#         #label = torch.Tensor.long(label[1])\n",
        "#         output = net(input1,input2)\n",
        "#         loss = criterion (output,label1)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "#         err.append(loss.item())\n",
        "#         if (i%5==0):\n",
        "#             print (loss,i,ep)\n",
        "#         \n",
        "#         if (i%50==0):\n",
        "#             val_index1 = np.random.permutation(val_index)[:100]\n",
        "#             val_dataloader = DataLoader(dataset,batch_size=30,sampler = SubsetRandomSampler(val_index1))\n",
        "#             val_iter = iter(val_dataloader)\n",
        "#     \n",
        "#             total = 0\n",
        "#             correct = 0\n",
        "#             for j,dataj in enumerate(val_dataloader):\n",
        "#                 input1j, input2j, labelj = dataj.items()\n",
        "#                 input1j, input2j = input1j[1].to(device), input2j[1].to(device)\n",
        "#                 \n",
        "#                 labelj = labelj[1].to(device)\n",
        "#                 output = net(input1j,input2j)\n",
        "#                 _,predicted = torch.max(output.data,1)\n",
        "#                 total +=labelj.size(0)\n",
        "#                 correct += (predicted == labelj).sum().item()\n",
        "#             print('Accuracy: %d %%'%(100*correct/total))\n",
        "#             acc.append(100*correct/total)\n",
        "#     save_checkpoint({\n",
        "#             'epoch': ep + 1,\n",
        "#             'state_dict': net.state_dict(),\n",
        "#             \n",
        "#             'optimizer' : optimizer.state_dict(),\n",
        "#         })\n",
        "#     \n",
        "# \n",
        "#         \n",
        "#         \n",
        "#         \n",
        "# \n",
        "#     \n",
        "# # sample = dataset[1]\n",
        "# # img = plt.imread(images_path+'000001.png')\n",
        "# # img2 = np.expand_dims(img,0)\n",
        "# # img3 = np.rollaxis(img2,3,1)\n",
        "# # output = Net(torch.from_numpy(img3))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}